{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c993224",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "Imagine you're developing a deep learning system tailored for sentiment analysis of product reviews, specifically for a newly established online beautiy product retail company. The goal is to assist the company in making informed decisions about inventory management â€“ deciding what products to retain and what to remove from stock. The company, keen on enhancing customer satisfaction, has been actively monitoring comments on their website and has invested in annotators to label sentiments. They hand you a dataset comprising 80,000 customer reviews, each labeled with 0 for negative sentiment and 1 for positive sentiment. After extensive effort and refinement, you successfully train and deploy a classifier that predicts sentiment based on online comments. Excitedly, you report an 86% accuracy on a held-out test set to your bosses. However, to your disappointment, management expresses dissatisfaction, insisting on a minimum of 90% accuracy before considering the widespread implementation of the AI model. \n",
    "You suspect that certain annotators might have made errors, potentially affecting your model's effectiveness. Empowered by a newfound \"confidence,\" you opt for \"confidence\" learning to pinpoint and rectify any inaccuracies in the dataset before embarking on the retraining process once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff3e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import json\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c2/w3')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime',\n",
    "                          config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm,\n",
    "                         sagemaker_runtime_client=sm_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df5c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# TODO: set the path to the train data\n",
    "train_data = TrainingInput(\n",
    "    ..., \n",
    "    content_type='application/x-sagemaker-training-data'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483e9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# TODO: create the estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point= \"main.py\",\n",
    "    source_dir= ...,\n",
    "    base_job_name=\"sagemaker-script-mode\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    framework_version=\"2.1\",\n",
    "    py_version=\"py310\",\n",
    "    dependencies= ...,\n",
    "    output_data_config={\n",
    "        'S3OutputPath': ...\n",
    "    },\n",
    "    output_path= ...,\n",
    "    environment={'PYTHONPATH': 'src'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb2d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model during training by specifying the output path\n",
    "# (Note: The output path should be where the best model will be saved within the S3 bucket)\n",
    "model_checkpoint = {\n",
    "    'ModelCheckpoint': {\n",
    "        'monitor': 'dev_loss',\n",
    "        'dirpath': '/opt/ml/model/',\n",
    "        'filename': 'best_model',\n",
    "        'save_top_k': 1,\n",
    "        'mode': 'min'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Attach the ModelCheckpoint callback to the estimator\n",
    "estimator._hyperparameters['callbacks'] = [model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d1f0fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: train the model\n",
    "estimator.fit({...})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a1af1",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "We need to copy the training artifacts, i.e, output.tar.gz, from the corresponding S3 bucket to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bca6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: copy the training artifacts from the S3 bucket to the current working directory\n",
    "!aws s3 cp ...      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2d885",
   "metadata": {},
   "source": [
    "#### We can decompress the training artifacts to `extracted_files` for further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67c743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf output.tar.gz -C extracted_training_artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905fef69",
   "metadata": {},
   "source": [
    "We then create an endpoint 'sentiment-analysis-endpoint-2' and deploy the model to that endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90c9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: deploy the trained model\n",
    "predictor = estimator.deploy(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092679b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_rev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
